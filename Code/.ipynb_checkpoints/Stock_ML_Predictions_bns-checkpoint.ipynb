{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#to plot within notebook\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import tree\n",
    "import sys\n",
    "import csv\n",
    "import datetime\n",
    "import pymysql\n",
    "from sqlalchemy import create_engine\n",
    "pymysql.install_as_MySQLdb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting figure size\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 20,10\n",
    "\n",
    "#for normalizing data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('mysql+mysqlconnector://root:root123@127.0.0.1:3306/stock_data')\n",
    "# df = pd.read_sql_query('select * from profile', con=engine)\n",
    "cfg_data = pd.read_sql_query('select * from cfg_data', con=engine)\n",
    "ms_data = pd.read_sql_query('select * from ms_data', con=engine)\n",
    "cme_data = pd.read_sql_query('select * from cme_data', con=engine)\n",
    "jpm_data = pd.read_sql_query('select * from jpm_data', con=engine)\n",
    "gs_data = pd.read_sql_query('select * from gs_data', con=engine)\n",
    "pypl_data = pd.read_sql_query('select * from pypl_data', con=engine)\n",
    "td_data = pd.read_sql_query('select * from td_data', con=engine)\n",
    "bns_data = pd.read_sql_query('select * from bns_data', con=engine)\n",
    "usb_data = pd.read_sql_query('select * from usb_data', con=engine)\n",
    "bmo_data = pd.read_sql_query('select * from bmo_data', con=engine)\n",
    "axp_data = pd.read_sql_query('select * from axp_data', con=engine)\n",
    "tech_data = pd.read_sql_query('select * from tech_data', con=engine)\n",
    "spx_data = pd.read_sql_query('select * from spx_data', con=engine)\n",
    "dow_data = pd.read_sql_query('select * from dow_data', con=engine)\n",
    "nasdaq_data = pd.read_sql_query('select * from nasdaq_data', con=engine)\n",
    "vix_data = pd.read_sql_query('select * from vix_data', con=engine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Symbols</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Adj_Close</th>\n",
       "      <th>Company_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1266</th>\n",
       "      <td>2019-07-24</td>\n",
       "      <td>axp</td>\n",
       "      <td>128.220001</td>\n",
       "      <td>126.790001</td>\n",
       "      <td>127.709999</td>\n",
       "      <td>127.949997</td>\n",
       "      <td>3628300.0</td>\n",
       "      <td>127.949997</td>\n",
       "      <td>American Express Company</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1267</th>\n",
       "      <td>2019-07-25</td>\n",
       "      <td>axp</td>\n",
       "      <td>128.190002</td>\n",
       "      <td>126.500000</td>\n",
       "      <td>127.809998</td>\n",
       "      <td>127.150002</td>\n",
       "      <td>2663500.0</td>\n",
       "      <td>127.150002</td>\n",
       "      <td>American Express Company</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1268</th>\n",
       "      <td>2019-07-26</td>\n",
       "      <td>axp</td>\n",
       "      <td>127.559998</td>\n",
       "      <td>126.300003</td>\n",
       "      <td>127.089996</td>\n",
       "      <td>126.779999</td>\n",
       "      <td>4236200.0</td>\n",
       "      <td>126.779999</td>\n",
       "      <td>American Express Company</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1269</th>\n",
       "      <td>2019-07-29</td>\n",
       "      <td>axp</td>\n",
       "      <td>127.459999</td>\n",
       "      <td>126.540001</td>\n",
       "      <td>126.910004</td>\n",
       "      <td>127.190002</td>\n",
       "      <td>1829500.0</td>\n",
       "      <td>127.190002</td>\n",
       "      <td>American Express Company</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1270</th>\n",
       "      <td>2019-07-30</td>\n",
       "      <td>axp</td>\n",
       "      <td>126.910004</td>\n",
       "      <td>126.300003</td>\n",
       "      <td>126.570000</td>\n",
       "      <td>126.470001</td>\n",
       "      <td>1575400.0</td>\n",
       "      <td>126.470001</td>\n",
       "      <td>American Express Company</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date Symbols        High         Low        Open       Close  \\\n",
       "1266 2019-07-24     axp  128.220001  126.790001  127.709999  127.949997   \n",
       "1267 2019-07-25     axp  128.190002  126.500000  127.809998  127.150002   \n",
       "1268 2019-07-26     axp  127.559998  126.300003  127.089996  126.779999   \n",
       "1269 2019-07-29     axp  127.459999  126.540001  126.910004  127.190002   \n",
       "1270 2019-07-30     axp  126.910004  126.300003  126.570000  126.470001   \n",
       "\n",
       "         Volume   Adj_Close              Company_name  \n",
       "1266  3628300.0  127.949997  American Express Company  \n",
       "1267  2663500.0  127.150002  American Express Company  \n",
       "1268  4236200.0  126.779999  American Express Company  \n",
       "1269  1829500.0  127.190002  American Express Company  \n",
       "1270  1575400.0  126.470001  American Express Company  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "axp_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #setting index as date\n",
    "# brk_data['Date'] = pd.to_datetime(brk_data.Date,format='%Y-%m-%d')\n",
    "# brk_data.index = ibkr_data['Date']\n",
    "\n",
    "# #plot\n",
    "# plt.figure(figsize=(16,8))\n",
    "# plt.plot(ibkr_data['Close'], label='Close Price history')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Long Short Term Memory (LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#importing required libraries\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = ibkr_data.sort_index(ascending=True, axis=0)\n",
    "# new_data = pd.DataFrame(index=range(0,len(ibkr_data)),columns=['Date', 'Close'])\n",
    "# for i in range(0,len(data)):\n",
    "#     new_data['Date'][i] = data['Date'][i]\n",
    "#     new_data['Close'][i] = data['Close'][i]\n",
    "\n",
    "# #setting index\n",
    "# new_data.index = new_data.Date\n",
    "# new_data.drop('Date', axis=1, inplace=True)\n",
    "\n",
    "# #creating train and test sets\n",
    "# dataset = new_data.values\n",
    "# data.iloc[1000:1010]\n",
    "# # train = dataset[0:987,:]\n",
    "# # valid = dataset[987:,:]\n",
    "\n",
    "# train = dataset[0:1007,:]\n",
    "# valid = dataset[1007:,:]\n",
    "\n",
    "# #converting dataset into x_train and y_train\n",
    "# scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "# scaled_data = scaler.fit_transform(dataset)\n",
    "\n",
    "# x_train, y_train = [], []\n",
    "# # 60 variance\n",
    "# for i in range(60,len(train)):\n",
    "#     x_train.append(scaled_data[i-60:i,0])\n",
    "#     y_train.append(scaled_data[i,0])\n",
    "# x_train, y_train = np.array(x_train), np.array(y_train)\n",
    "\n",
    "# x_train = np.reshape(x_train, (x_train.shape[0],x_train.shape[1],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # create and fit the LSTM network\n",
    "# model = Sequential()\n",
    "# model.add(LSTM(units=50, return_sequences=True, input_shape=(x_train.shape[1],1)))\n",
    "# model.add(LSTM(units=50))\n",
    "# model.add(Dense(1))\n",
    "\n",
    "# model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "# model.fit(x_train, y_train, epochs=1, batch_size=1, verbose=2)\n",
    "\n",
    "# #predicting 246 values, using past 60 from the train data\n",
    "# inputs = new_data[len(new_data) - len(valid) - 60:].values\n",
    "# inputs = inputs.reshape(-1,1)\n",
    "# inputs  = scaler.transform(inputs)\n",
    "\n",
    "# X_test = []\n",
    "# for i in range(60,inputs.shape[0]):\n",
    "#     X_test.append(inputs[i-60:i,0])\n",
    "# X_test = np.array(X_test)\n",
    "\n",
    "# X_test = np.reshape(X_test, (X_test.shape[0],X_test.shape[1],1))\n",
    "# closing_price = model.predict(X_test)\n",
    "# closing_price = scaler.inverse_transform(closing_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rms=np.sqrt(np.mean(np.power((valid-closing_price),2)))\n",
    "# rms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valid.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Symbols</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Adj_Close</th>\n",
       "      <th>Company_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1266</th>\n",
       "      <td>2019-07-24</td>\n",
       "      <td>ms</td>\n",
       "      <td>45.709999</td>\n",
       "      <td>44.860001</td>\n",
       "      <td>44.889999</td>\n",
       "      <td>45.500000</td>\n",
       "      <td>8092200.0</td>\n",
       "      <td>45.147911</td>\n",
       "      <td>Morgan Stanley</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1267</th>\n",
       "      <td>2019-07-25</td>\n",
       "      <td>ms</td>\n",
       "      <td>45.570000</td>\n",
       "      <td>44.599998</td>\n",
       "      <td>45.500000</td>\n",
       "      <td>44.869999</td>\n",
       "      <td>8733800.0</td>\n",
       "      <td>44.522785</td>\n",
       "      <td>Morgan Stanley</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1268</th>\n",
       "      <td>2019-07-26</td>\n",
       "      <td>ms</td>\n",
       "      <td>45.770000</td>\n",
       "      <td>44.910000</td>\n",
       "      <td>44.990002</td>\n",
       "      <td>45.740002</td>\n",
       "      <td>8321000.0</td>\n",
       "      <td>45.386055</td>\n",
       "      <td>Morgan Stanley</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1269</th>\n",
       "      <td>2019-07-29</td>\n",
       "      <td>ms</td>\n",
       "      <td>45.730000</td>\n",
       "      <td>45.070000</td>\n",
       "      <td>45.639999</td>\n",
       "      <td>45.230000</td>\n",
       "      <td>8667000.0</td>\n",
       "      <td>44.880001</td>\n",
       "      <td>Morgan Stanley</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1270</th>\n",
       "      <td>2019-07-30</td>\n",
       "      <td>ms</td>\n",
       "      <td>44.849998</td>\n",
       "      <td>44.169998</td>\n",
       "      <td>44.610001</td>\n",
       "      <td>44.669998</td>\n",
       "      <td>7317900.0</td>\n",
       "      <td>44.669998</td>\n",
       "      <td>Morgan Stanley</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date Symbols       High        Low       Open      Close  \\\n",
       "1266 2019-07-24      ms  45.709999  44.860001  44.889999  45.500000   \n",
       "1267 2019-07-25      ms  45.570000  44.599998  45.500000  44.869999   \n",
       "1268 2019-07-26      ms  45.770000  44.910000  44.990002  45.740002   \n",
       "1269 2019-07-29      ms  45.730000  45.070000  45.639999  45.230000   \n",
       "1270 2019-07-30      ms  44.849998  44.169998  44.610001  44.669998   \n",
       "\n",
       "         Volume  Adj_Close    Company_name  \n",
       "1266  8092200.0  45.147911  Morgan Stanley  \n",
       "1267  8733800.0  44.522785  Morgan Stanley  \n",
       "1268  8321000.0  45.386055  Morgan Stanley  \n",
       "1269  8667000.0  44.880001  Morgan Stanley  \n",
       "1270  7317900.0  44.669998  Morgan Stanley  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ms_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bns_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-e6afbda2d787>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# df_data = [\"cfg_data\",\"ms_data\",\"cme_data\",\"jpm_data\",\"gs_data\",\"pypl_data\",\"td_data\",\"brk_data\",\"usb_data\",\"ibkr_data\",\"axp_data\"]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbns_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mascending\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mnew_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbrk_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Date'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Close'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'bns_data' is not defined"
     ]
    }
   ],
   "source": [
    "# df_data = [\"cfg_data\",\"ms_data\",\"cme_data\",\"jpm_data\",\"gs_data\",\"pypl_data\",\"td_data\",\"brk_data\",\"usb_data\",\"ibkr_data\",\"axp_data\"]\n",
    "\n",
    "data = bns_data.sort_index(ascending=True, axis=0)\n",
    "new_data = pd.DataFrame(index=range(0,len(brk_data)),columns=['Date', 'Close'])\n",
    "for i in range(0,len(data)):\n",
    "    new_data['Date'][i] = data['Date'][i]\n",
    "    new_data['Close'][i] = data['Close'][i]\n",
    "\n",
    "#setting index\n",
    "new_data.index = new_data.Date\n",
    "new_data.drop('Date', axis=1, inplace=True)\n",
    "\n",
    "#creating train and test sets\n",
    "dataset = new_data.values\n",
    "\n",
    "# train = dataset[0:987,:]\n",
    "# valid = dataset[987:,:]\n",
    "\n",
    "train = dataset[0:1020,:]\n",
    "valid = dataset[1020:,:]\n",
    "\n",
    "#converting dataset into x_train and y_train\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_data = scaler.fit_transform(dataset)\n",
    "\n",
    "x_train, y_train = [], []\n",
    "for i in range(60,len(train)):\n",
    "    x_train.append(scaled_data[i-60:i,0])\n",
    "    y_train.append(scaled_data[i,0])\n",
    "x_train, y_train = np.array(x_train), np.array(y_train)\n",
    "\n",
    "x_train = np.reshape(x_train, (x_train.shape[0],x_train.shape[1],1))\n",
    "\n",
    "# create and fit the LSTM network\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(x_train.shape[1],1)))\n",
    "model.add(LSTM(units=50))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(x_train, y_train, epochs=1, batch_size=1, verbose=2)\n",
    "\n",
    "#predicting 246 values, using past 60 from the train data\n",
    "inputs = new_data[len(new_data) - len(valid) - 60:].values\n",
    "inputs = inputs.reshape(-1,1)\n",
    "inputs  = scaler.transform(inputs)\n",
    "\n",
    "X_test = []\n",
    "for i in range(60,inputs.shape[0]):\n",
    "    X_test.append(inputs[i-60:i,0])\n",
    "X_test = np.array(X_test)\n",
    "\n",
    "X_test = np.reshape(X_test, (X_test.shape[0],X_test.shape[1],1))\n",
    "closing_price = model.predict(X_test)\n",
    "closing_price = scaler.inverse_transform(closing_price)\n",
    "\n",
    "valid = new_data[1020:]\n",
    "valid['Predictions'] = closing_price\n",
    "ml_data = valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for plotting\n",
    "# train = new_data[:1004]\n",
    "valid = new_data[1020:]\n",
    "valid['Predictions'] = closing_price\n",
    "# plt.plot(train['Close'])\n",
    "plt.plot(valid[['Close','Predictions']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[1000:1025]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_data['Symbols']= 'bns'\n",
    "ml_data = ml_data.reset_index()\n",
    "ml_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for plotting\n",
    "# train = new_data[:1004]\n",
    "valid = new_data[1020:]\n",
    "valid['Predictions'] = closing_price\n",
    "# plt.plot(train['Close'])\n",
    "plt.plot(valid[['Close','Predictions']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading into Database Mysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('mysql+mysqlconnector://root:root123@127.0.0.1:3306/stock_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ml_data.to_sql(name='cfg_data_LSTM', con=engine, if_exists = 'replace', index=False)\n",
    "# ml_data.to_sql(name='ms_data_lstm', con=engine, if_exists = 'append', index=False)\n",
    "# ml_data.to_sql(name='cme_data_lstm', con=engine, if_exists = 'replace', index=False)\n",
    "# ml_data.to_sql(name='jpm_data_lstm', con=engine, if_exists = 'append', index=False)\n",
    "# ml_data.to_sql(name='gs_data_lstm', con=engine, if_exists = 'append', index=False)\n",
    "# ml_data.to_sql(name='pypl_data_lstm', con=engine, if_exists = 'append', index=False)\n",
    "# ml_data.to_sql(name='td_data_lstm', con=engine, if_exists = 'replace', index=False)\n",
    "ml_data.to_sql(name='bns_data_lstm', con=engine, if_exists = 'append', index=False)\n",
    "# ml_data.to_sql(name='usb_data_LSTM', con=engine, if_exists = 'append', index=False)\n",
    "# ml_data.to_sql(name='ibkr_data_LSTM', con=engine, if_exists = 'append', index=False)\n",
    "# ml_data.to_sql(name='axp_data_LSTM', con=engine, if_exists = 'replace', index=False)\n",
    "# ml_data.to_sql(name='tech_data_LSTM', con=engine, if_exists = 'append', index=False)\n",
    "# ml_data.to_sql(name='all_data_LSTM', con=engine, if_exists = 'append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_sql_query('select * from bns_data_lstm', con=engine).tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bns_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
